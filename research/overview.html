<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Research - MasVisio Research</title>
  <meta name="description"
    content="Overview of MasVisio Research programs including 4D myopia control, AI diagnostics, and biometric measurement." />
  <meta property="og:title" content="Research Overview - MasVisio Research" />
  <meta property="og:description"
    content="Overview of MasVisio Research programs including 4D myopia control, AI diagnostics, and biometric measurement." />
  <meta property="og:type" content="website" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="../assets/css/main.css?v=1.4" />
  <link rel="stylesheet" href="../assets/css/responsive.css?v=1.4" />
  <link rel="stylesheet" href="../assets/css/components.css?v=1.4" />
</head>

<body class="sidebar-layout">
  <header class="mobile-header">
    <a href="../index.html" class="mobile-logo">
      <h1>MasVisio<br />Research</h1>
      <span class="logo-subtitle">Vision Intelligence &<br />Biomedical Engineering</span>
    </a>
  </header>

  <aside class="sidebar">
    <div class="sidebar-header">
      <a href="../index.html" class="sidebar-logo">
        <h1>MasVisio Research</h1>
        <span class="sidebar-subtitle">Vision Intelligence &<br />Biomedical Engineering</span>
      </a>
    </div>

    <div class="lang-switch">
      <a href="../ko/research/overview.html">ðŸ‡°ðŸ‡·</a>
      <span class="active">ðŸ‡¬ðŸ‡§</span>
    </div>

    <nav class="sidebar-nav">
      <a href="../index.html" class="nav-item">Home</a>
      <a href="../team/index.html" class="nav-item">Team</a>
      <a href="overview.html" class="nav-item active">Challenges</a>
      <a href="../publications/index.html" class="nav-item">Publications</a>
      <a href="../gallery/index.html" class="nav-item">Gallery</a>
      <a href="../partnership/index.html" class="nav-item">Services</a>
      <a href="../contact.html" class="nav-item">Partners</a>
    </nav>

    <div class="sidebar-footer">
      <p class="copyright">&copy; 2025 MasVisio Research</p>
      <div style="margin-top: 10px; font-size: 0.7rem">
        <a href="../privacy.html" style="color: #94a3b8; text-decoration: none">Privacy Policy</a>
        |
        <a href="../contact.html" style="color: #94a3b8; text-decoration: none">Contact</a>
      </div>
    </div>
  </aside>

  <main class="main-content">
    <section class="section" style="padding: 4rem 5%">
      <div class="container">
        <!-- Hero Section Removed -->

        <!-- Lead Introduction -->
        <div class="challenge-list">
          <!-- Lead text removed -->

          <!-- PHASE 1: Visual Neuroscience -->
          <div class="challenge-section">
            <span class="challenge-phase-label">Phase 1: Visual Neuroscience</span>
            <h2 class="challenge-title">
              Decoding the <strong>Neural Code</strong>
            </h2>

            <p class="challenge-desc">
              Before we can correct vision, we must understand how the brain
              processes it. Our research begins at the foundational level:
              analyzing how visual pathways interpret motion and contrast to
              distinguish between optical deficits and neurological processing
              issues.
            </p>

            <div class="challenge-visual-container">
              <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a">
                Motion Contrast Sensitivity
              </h3>

              <p style="
                    font-size: 0.95rem;
                    color: #475569;
                    margin-bottom: 2rem;
                    line-height: 1.6;
                  ">
                Contrast sensitivity measures the visual system's ability to
                distinguish objects from their background, a critical
                indicator of functional vision beyond standard acuity. We
                utilize <strong>Gabor patches</strong>â€”sinusoidal gratings
                modulated by a Gaussian envelopeâ€”to precisely probe spatial
                and temporal summation mechanisms. By varying the size and
                duration of these stimuli, we can map the receptive field
                properties of visual neurons and isolate deficits in specific
                neural channels.
              </p>

              <!-- Spatial/Temporal frequency GIFs (same-size left/right boxes) -->
              <div style="
                    margin-bottom: 2rem;
                    display: flex;
                    gap: 2rem;
                    justify-content: center;
                    flex-wrap: nowrap;
                    align-items: flex-start;
                  ">
                <figure style="flex: 0 1 127px; margin: 0; text-align: center">
                  <div style="
                        position: relative;
                        width: 127px;
                        height: 127px;
                        border: 1px solid #e2e8f0;
                        border-radius: 0;
                        background: #f1f5f9;
                        overflow: hidden;
                        transform: translateX(6mm);
                      ">
                    <img src="../assets/images/gabor_spatial_frequency.gif"
                      alt="Gabor Patch Spatial Frequency Variation (1-30 cpd)" style="
                          position: absolute;
                          inset: 0;
                          width: 100%;
                          height: 100%;
                          object-fit: contain;
                          display: block;
                        " loading="lazy" />
                  </div>
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.9rem;
                        color: #94a3b8;
                        text-align: center;
                        white-space: nowrap;
                        height: 1.4em;
                        line-height: 1.4em;
                        overflow: hidden;
                        transform: translateX(3mm);
                      " data-gabor-caption="true" data-caption-start="1" data-caption-end="30" data-caption-frames="30"
                    data-caption-duration="4500">
                    <span class="gabor-caption-label">spatial frequency:</span>
                    <span class="gabor-caption-value" style="
                          display: inline-block;
                          min-width: 2ch;
                          text-align: right;
                        ">1</span>
                    <span class="gabor-caption-unit">cpd</span>
                  </figcaption>
                </figure>
                <figure style="flex: 0 1 127px; margin: 0; text-align: center">
                  <div data-temporal-flicker="canvas" data-freq-start="1" data-freq-end="30" data-ramp-duration="12000"
                    data-step-duration="400" data-speed-multiplier="2.5"
                    data-on-src="../assets/images/temporal_frequency_on.png"
                    data-off-src="../assets/images/temporal_frequency_off.png" style="
                        position: relative;
                        width: 127px;
                        height: 127px;
                        border: 1px solid #e2e8f0;
                        border-radius: 0;
                        background: #f1f5f9;
                        overflow: hidden;
                        transform: translateX(6mm);
                      ">
                    <canvas class="temporal-flicker-canvas" style="width: 100%; height: 100%; display: block"></canvas>
                  </div>
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.9rem;
                        color: #94a3b8;
                        text-align: center;
                        white-space: nowrap;
                        height: 1.4em;
                        line-height: 1.4em;
                        overflow: hidden;
                        transform: translateX(-3.5mm);
                      " data-temporal-caption="true">
                    <span class="gabor-caption-label">temporal frequency:</span>
                    <span class="temporal-caption-value" style="
                          display: inline-block;
                          min-width: 2ch;
                          text-align: right;
                        ">1</span>
                    <span class="gabor-caption-unit">Hz</span>
                  </figcaption>
                </figure>
              </div>

              <div class="challenge-visual-grid">
                <figure>
                  <img src="../assets/images/contrast_sensitivity_plot.png" alt="Contrast Sensitivity Plot" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.9rem;
                        color: #94a3b8;
                        text-align: center;
                      ">
                    Sensitivity Thresholds
                  </figcaption>
                </figure>
                <figure>
                  <img src="../assets/images/contrast_sensitivity_boxplot.png" alt="Contrast Sensitivity Boxplot" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.9rem;
                        color: #94a3b8;
                        text-align: center;
                      ">
                    Population Analytics
                  </figcaption>
                </figure>
              </div>

              <p style="
                    font-size: 0.95rem;
                    color: #475569;
                    margin-top: 2rem;
                    line-height: 1.6;
                  ">
                <strong style="color: #0f172a">Key Findings:</strong> The
                sensitivity threshold analysis reveals distinct functional
                baselines across age groups, with the boxplot demonstrating
                significant variance in the older demographic. This data
                establishes a quantitative standard for detecting subtle
                neural degradation before structural damage becomes visible.
              </p>
            </div>
          </div>

          <!-- Connector -->
          <div class="story-connector"></div>

          <!-- PHASE 2: Optical Metrology -->
          <div class="challenge-section">
            <span class="challenge-phase-label">Phase 2: Optometric Metrology</span>
            <h2 class="challenge-title">
              Mysteries of the Eye's 6 Interfaces: <strong>Refraction</strong>
            </h2>

            <p class="challenge-desc">
              Myopia progression is not merely an increase in axial length but
              is closely related to morphological changes in the peripheral
              retina. We precisely analyze the changes in peripheral retinal
              curvature radius according to spherical equivalent refraction
              along each meridian to quantitatively determine the impact of
              the degree of myopia on the geometrical structure of the retina.
            </p>

            <div class="challenge-visual-container">
              <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a">
                Precise Geometrical Optics Modeling & Simulation
              </h3>

              <p style="
                    font-size: 0.95rem;
                    color: #475569;
                    margin-bottom: 2rem;
                    line-height: 1.6;
                  ">
                Since 2014, we have conducted research applying a proprietary
                calculation algorithm that has been continuously refined. We
                precisely calculate all angles of incidence and refraction
                from a geometric optical perspective at
                <strong>a total of 6 refractive surfaces: anterior/posterior
                  cornea, anterior/posterior lens cortex, and
                  anterior/posterior lens nucleus</strong>. This precise <strong>Ray-tracing</strong>
                simulation accurately predicts the final convergence point on
                the retina and, combined with retinal data measured from 0â€“315
                degrees using DRI OCT Triton, perfectly verifies the
                correlation between refractive error and retinal shape.
              </p>

              <!-- Images resized to be compact (similar to Phase 1) and arranged in a row -->
              <div class="challenge-visual-grid" style="
                    display: flex;
                    gap: 1rem;
                    justify-content: center;
                    flex-wrap: wrap;
                  ">
                <figure style="
                      flex: 0 1 220px;
                      background: #f8fafc;
                      padding: 0.5rem;
                      border-radius: 8px;
                      border: 1px solid #e2e8f0;
                    ">
                  <img src="../assets/images/research/phase2/oct_analysis.png" alt="Retinal OCT Measurement"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.8rem;
                        color: #64748b;
                        text-align: center;
                      ">
                    OCT Retinal Curvature Measurement
                  </figcaption>
                </figure>

                <figure style="
                      flex: 0 1 220px;
                      background: #f8fafc;
                      padding: 0.5rem;
                      border-radius: 8px;
                      border: 1px solid #e2e8f0;
                    ">
                  <img src="../assets/images/research/phase2/optical_simulation.png" alt="Ray-tracing Simulation"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.8rem;
                        color: #64748b;
                        text-align: center;
                      ">
                    6-Surface Ray-tracing
                  </figcaption>
                </figure>

                <figure style="
                      flex: 0 1 220px;
                      background: #f8fafc;
                      padding: 0.5rem;
                      border-radius: 8px;
                      border: 1px solid #e2e8f0;
                    ">
                  <img src="../assets/images/research/phase2/curvature_graph.png" alt="Curvature Change Graph"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.8rem;
                        color: #64748b;
                        text-align: center;
                      ">
                    Retinal Shape by Refractive Error
                  </figcaption>
                </figure>
              </div>

              <p style="
                    font-size: 0.95rem;
                    color: #475569;
                    margin-top: 2rem;
                    line-height: 1.6;
                  ">
                <strong style="color: #0f172a">Key Findings:</strong>
                A strong positive correlation (r=0.836) was confirmed between
                spherical equivalent refraction and retinal curvature radius.
                In particular, the most distinct changes were observed in the
                <strong>Temporal and Inferior retina</strong>, suggesting that
                the retina expands asymmetrically in specific directions
                during myopia progression.
              </p>

            </div>

            <!-- Connector for second approach -->
            <div class="story-connector" style="margin: 2rem auto"></div>

            <h2 class="challenge-title" style="margin-top: 0">
              Calculating <strong>Peripheral Retinal Focus</strong> via Chromatic Aberration
            </h2>

            <p class="challenge-desc">
              To accurately measure the refractive state of the peripheral retina, we utilize the principle of
              <strong>Longitudinal Chromatic Aberration</strong> between Red and Green wavelengths.
            </p>

            <div class="challenge-visual-container">
              <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a;">
                Chromatic Aberration-based Peripheral Refraction Measurement
              </h3>

              <p style="font-size: 0.95rem; color: #475569; margin-bottom: 1.5rem; line-height: 1.6;">
                First, we establish iso-visibility of 1cpd Red/Green Gabor Patches at the fovea.
                Then, by conducting flicker tests using LED rings placed at 8Â°, 16Â°, and 32Â° in the periphery, we
                calculate the refractive power at each eccentricity.
              </p>

              <!-- Logic Box -->
              <div
                style="margin-bottom: 2rem; padding: 1.5rem; background: #f8fafc; border-radius: 8px; border: 1px solid #e2e8f0;">
                <h4 style="font-size: 1rem; margin-bottom: 0.8rem; color: #334155;">Measurement Logic</h4>
                <ul
                  style="list-style: none; padding: 0; margin-bottom: 1rem; font-size: 0.9rem; color: #475569; line-height: 1.7;">
                  <li style="margin-bottom: 0.5rem;"><strong>Step 1. Iso-clarity Calibration:</strong> Establish
                    subjective iso-clarity baseline by measuring contrast sensitivity of 1cpd Red/Green patches in the
                    central field.</li>
                  <li style="margin-bottom: 0.5rem;"><strong>Step 2. Peripheral Stimulation:</strong> Randomly flicker
                    Red/Green LED pairs arranged on concentric circles at 8Â°, 16Â°, and 32Â°.</li>
                  <li style="margin-bottom: 0.5rem;"><strong>Step 3. Refraction Calculation:</strong> Inverse
                    calculate the focal position (defocus) on the retina by analyzing the subject's clarity response
                    pattern for each color.</li>
                </ul>
                <div
                  style="margin-top: 1rem; padding: 1rem; background: #fff; border-radius: 4px; text-align: center; border: 1px solid #e2e8f0;">
                  <div
                    style="font-family: 'Times New Roman', serif; font-size: 1.1rem; color: #0f172a; margin-bottom: 0.5rem;">
                    <em>R</em><sub>ecc</sub> = <em>R</em><sub>fovea</sub> + &alpha; &middot;
                    log(<em>S</em><sub>red</sub> / <em>S</em><sub>green</sub>)
                  </div>
                  <span style="font-size: 0.8rem; color: #94a3b8;">
                    (<em>R</em>: Refraction, &alpha;: Chromatic Coefficient, <em>S</em>: Sensitivity)
                  </span>
                </div>
              </div>

              <!-- Images -->
              <div class="challenge-visual-grid"
                style="display: flex; gap: 1rem; justify-content: center; flex-wrap: wrap;">
                <figure
                  style="flex: 0 1 220px; background: #f8fafc; padding: 0.5rem; border-radius: 8px; border: 1px solid #e2e8f0;">
                  <img src="../assets/images/research/phase2/peripheral_setup_schematic.png"
                    alt="Experimental Setup Schematic"
                    style="width: 100%; height: 180px; object-fit: cover; border-radius: 4px;">
                  <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                    Peripheral Retinal Full-correction Pilot Study</figcaption>
                </figure>
                <figure
                  style="flex: 0 1 220px; background: #f8fafc; padding: 0.5rem; border-radius: 8px; border: 1px solid #e2e8f0;">
                  <img src="../assets/images/research/phase2/led_flicker.gif" alt="LED Ring Circuit Design"
                    style="width: 100%; height: 180px; object-fit: cover; border-radius: 4px;">
                  <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">LED
                    Control Circuit Diagram</figcaption>
                </figure>
                <figure
                  style="flex: 0 1 220px; background: #f8fafc; padding: 0.5rem; border-radius: 8px; border: 1px solid #e2e8f0;">
                  <img src="../assets/images/research/phase2/peripheral_prototype.gif" alt="Peripheral Prototype"
                    style="width: 100%; height: 180px; object-fit: cover; border-radius: 4px;">
                  <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                    Peripheral Retinal Full-correction Prototype</figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!-- Connector -->
          <div class="story-connector"></div>

          <!-- PHASE 3: Prototype Development -->
          <div class="challenge-section">
            <span class="challenge-phase-label">Phase 3: Prototype Development</span>
            <h2 class="challenge-title">
              Real-time <strong>Auto Refractometer</strong>
            </h2>

            <p class="challenge-desc">
              We have developed an innovative system that measures refractive
              error by analyzing the brightness, thickness, and movement speed
              of the Retinal Shadowâ€”a subtle pattern of light reflected from
              the eye. Our proprietary Retinoscopy model is continuously
              updated, calculating refractive errors in real-time based on
              probabilistic models.
            </p>

            <div class="challenge-visual-container">
              <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a">
                Machine Learning-based Real-time Retinoscopy Analysis Process
              </h3>

              <!-- Images arranged in a row -->
              <div class="challenge-visual-grid" style="
                    display: flex;
                    gap: 1rem;
                    justify-content: center;
                    flex-wrap: wrap;
                    align-items: flex-start;
                  ">
                <figure style="
                      flex: 0 1 330px;
                      background: #f8fafc;
                      padding: 0.5rem;
                      border-radius: 8px;
                      border: 1px solid #e2e8f0;
                    ">
                  <img src="../assets/images/research/phase3/auto_ref_device.png"
                    alt="Real-time Auto Refractometer Prototype"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.8rem;
                        color: #64748b;
                        text-align: center;
                      ">
                    Real-time Auto Refractometer Prototype
                  </figcaption>
                </figure>

                <figure style="
                      flex: 0 1 638px;
                      background: #f8fafc;
                      padding: 0.5rem;
                      border-radius: 8px;
                      border: 1px solid #e2e8f0;
                    ">
                  <img src="../assets/images/research/phase3/retinoscopy_view.png" alt="Retinal Shadow Pattern Analysis"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.8rem;
                        color: #64748b;
                        text-align: center;
                      ">
                    Real-time Image Processing of Retinal Shadow
                  </figcaption>
                </figure>

                <figure style="
                      flex: 0 1 440px;
                      background: #f8fafc;
                      padding: 0.5rem;
                      border-radius: 8px;
                      border: 1px solid #e2e8f0;
                    ">
                  <img src="../assets/images/research/phase3/ai_process_flow.png" alt="AI Learning & Output Process"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                        margin-top: 0.5rem;
                        font-size: 0.8rem;
                        color: #64748b;
                        text-align: center;
                      ">
                    Inference Pipeline for Real-time Processed Images
                  </figcaption>
                </figure>
              </div>
            </div>

            <!-- Connector for Item 2 -->
            <div class="story-connector" style="margin: 3rem auto"></div>

            <h2 class="challenge-title" style="margin-top: 0">
              Corneo-scleral <strong>3D Reconstruction</strong>
            </h2>
            <p class="challenge-desc">
              We are developing technology to precisely measure the 3D shape
              of the cornea and sclera by projecting Infrared Structured Light
              Patterns onto the eye surface. By reconstructing the captured
              pattern images using Mesh techniques, we visualize the profile
              of the cornea and sclera in 3D. This provides key quantitative
              data for prescribing custom scleral lenses that perfectly fit
              individual eye shapes.
            </p>

            <div class="challenge-visual-container">
              <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a">
                Structured Light Pattern-based 3D Shape Restoration
              </h3>

              <!-- Logic Pipeline & Formula Description -->
              <div style="margin-bottom: 2rem; padding: 1.5rem; background: #f1f5f9; border-radius: 8px;">
                <h4 style="font-size: 1rem; margin-bottom: 1rem; color: #334155;">Logic Pipeline</h4>
                <ul
                  style="list-style: none; padding: 0; margin-bottom: 1.5rem; font-size: 0.95rem; color: #475569; line-height: 1.8;">
                  <li style="margin-bottom: 0.5rem;">
                    <strong>1. Pattern Projection:</strong> Infrared LED concentric circles are projected onto the eye
                    surface at regular intervals
                  </li>
                  <li style="margin-bottom: 0.5rem;">
                    <strong>2. Distortion Analysis:</strong> Measuring distance differences and distortions of
                    concentric circle patterns deformed by corneal and scleral curvature
                  </li>
                  <li style="margin-bottom: 0.5rem;">
                    <strong>3. Shape Recovery:</strong> Converting ring pattern displacement into height information
                    <div
                      style="margin: 0.8rem 0; padding: 0.8rem; background: #fff; border-radius: 4px; text-align: center; font-family: 'Times New Roman', serif; font-size: 1.1rem; color: #0f172a;">
                      <em>Z</em>(<em>r</em>) &propto; &Delta;<em>d</em> &middot; tan(&theta;)
                    </div>
                    <span style="font-size: 0.85rem; color: #64748b; display: block; text-align: right;">(<em>Z</em>:
                      Surface Height, &Delta;<em>d</em>: Pattern Displacement, &theta;: Projection Angle)</span>
                  </li>
                  <li>
                    <strong>4. Mesh Generation:</strong> Implementing precise 3D topography mesh by connecting recovered
                    point cloud coordinates
                  </li>
                </ul>
              </div>

              <div class="challenge-visual-grid" style="
                    display: flex;
                    gap: 1rem;
                    justify-content: center;
                    flex-wrap: wrap;
                    align-items: flex-start;
                  ">
                <figure style="
                        flex: 0 1 506px;
                        background: #f8fafc;
                        padding: 0.5rem;
                        border-radius: 8px;
                        border: 1px solid #e2e8f0;
                      ">
                  <img src="../assets/images/research/phase3/structured_light_process.jpg"
                    alt="Structured Light Pattern Image Processing"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                          margin-top: 0.5rem;
                          font-size: 0.8rem;
                          color: #64748b;
                          text-align: center;
                        ">
                    Infrared Pattern Projection & Image Processing Pipeline
                  </figcaption>
                </figure>

                <figure style="
                        flex: 0 1 374px;
                        background: #f8fafc;
                        padding: 0.5rem;
                        border-radius: 8px;
                        border: 1px solid #e2e8f0;
                      ">
                  <img src="../assets/images/research/phase3/3d_reconstruction_method.png"
                    alt="3D Reconstruction Algorithm and Deep Learning Model"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                          margin-top: 0.5rem;
                          font-size: 0.8rem;
                          color: #64748b;
                          text-align: center;
                        ">
                    Selective Calculation: Physical vs ML-based Statistical Methods
                  </figcaption>
                </figure>

                <figure style="
                        flex: 0 1 440px;
                        background: #f8fafc;
                        padding: 0.5rem;
                        border-radius: 8px;
                        border: 1px solid #e2e8f0;
                      ">
                  <img src="../assets/images/research/phase3/corneo_scleral_analysis_ui.png"
                    alt="Real-time Corneo-Scleral Analysis Software UI"
                    style="width: 100%; height: auto; border-radius: 4px" />
                  <figcaption style="
                          margin-top: 0.5rem;
                          font-size: 0.8rem;
                          color: #64748b;
                          text-align: center;
                        ">
                    Real-time Corneo-Scleral 3D Analysis Software (Real-time Analysis UI)
                  </figcaption>
                </figure>
              </div>
            </div>

            <!-- Connector -->
            <div class="story-connector"></div>

            <!-- PHASE 4: AI Disease Prediction -->
            <div class="challenge-section">
              <span class="challenge-phase-label">Phase 4: AI Disease Prediction</span>
              <h2 class="challenge-title">
                Pupil Response-based <strong>AI Biomarkers</strong>
              </h2>
              <p class="challenge-desc">
                The pupil is a physiological window that reflects the activity of the autonomic nervous system. We
                analyze minute changes in pupil response using ultra-precision computer vision and AI algorithms to
                research innovative screening technologies that capture everything from unconscious cognitive processes
                to signs of neurological diseases.
              </p>

              <!-- Study 1: Brain Hacking -->
              <div class="challenge-visual-container" style="margin-top: 3rem;">
                <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a;">
                  Study 1: 'Brain Hacking' - Sexual Preference & Lifestyle Analysis
                </h3>

                <div
                  style="background: #f8fafc; padding: 1.5rem; border-radius: 8px; border: 1px solid #e2e8f0; margin-bottom: 2rem;">
                  <h4 style="font-size: 1rem; margin-bottom: 1rem; color: #334155; font-weight: 600;">Research Overview
                  </h4>
                  <p style="font-size: 0.95rem; color: #475569; line-height: 1.7; margin-bottom: 1rem;">
                    This study proposed a methodology to objectively evaluate unconscious human sexual preferences
                    through pupil responses. We established an infrared pupil tracking system based on a Basler
                    high-speed industrial camera and a fixed-focus lens, and developed a pipeline to precisely extract
                    and analyze minute pupil changes and response speeds from video data using our proprietary
                    OpenCV-based algorithm.
                  </p>

                  <!-- Phase 4 Images -->
                  <div class="challenge-visual-grid"
                    style="display: flex; gap: 1rem; justify-content: center; flex-wrap: wrap; margin-bottom: 1.5rem;">
                    <!-- 1. Experiment Scene -->
                    <figure
                      style="flex: 1 1 auto; max-width: 249px; background: #fff; padding: 0.5rem; border: 1px solid #e2e8f0; border-radius: 8px;">
                      <img src="../assets/images/research/phase4_experiment_scene_new.jpg" alt="Experiment Scene"
                        style="width: auto; max-width: 100%; height: auto; border-radius: 4px;">
                      <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                        Clear image acquisition even in low light with IR
                      </figcaption>
                    </figure>

                    <!-- 2. Eye Tracking Monitor -->
                    <figure
                      style="flex: 1 1 auto; max-width: 247px; background: #fff; padding: 0.5rem; border: 1px solid #e2e8f0; border-radius: 8px;">
                      <img src="../assets/images/research/phase4_eye_tracking_monitor.jpg" alt="Eye Tracking Monitor"
                        style="width: auto; max-width: 100%; height: auto; border-radius: 4px;">
                      <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                        Automated calculation & output of 10 pupil metrics after real-time ROI detection
                      </figcaption>
                    </figure>

                    <!-- 3. Pupil Graph -->
                    <figure
                      style="flex: 1 1 auto; max-width: 1000px; background: #fff; padding: 0.5rem; border: 1px solid #e2e8f0; border-radius: 8px;">
                      <img src="../assets/images/research/phase4_pupil_graph.jpg" alt="Pupil Response Graph"
                        style="width: 100%; height: auto; border-radius: 4px;">
                      <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                        Time-series Pupil Response Analysis by Stimulus
                      </figcaption>
                    </figure>
                  </div>

                  <h4
                    style="font-size: 1rem; margin-bottom: 1rem; color: #334155; font-weight: 600; margin-top: 1.5rem;">
                    Key Findings</h4>
                  <ul style="list-style: none; padding: 0; font-size: 0.95rem; color: #475569; line-height: 1.7;">
                    <li style="margin-bottom: 0.8rem; padding-left: 1rem; border-left: 3px solid #3b82f6;">
                      <strong>Sexual Orientation Detection:</strong> Men showed significantly larger pupil responses to
                      female images, and women to male images (p&lt;0.001). Notably, the difference in response for
                      women was 2.4 times more distinct than that of men.
                    </li>
                    <li style="margin-bottom: 0.8rem; padding-left: 1rem; border-left: 3px solid #3b82f6;">
                      <strong>Impact of Lifestyle:</strong> Smokers had a lower ratio of 'immediate response' during
                      stimulus transition compared to non-smokers (0.88 times), but the magnitude of change was
                      significantly larger, confirming the complex effect of nicotine on autonomic reactivity.
                    </li>
                  </ul>
                </div>
              </div>

              <!-- Connector between studies -->
              <div class="story-connector" style="margin: 2rem auto;"></div>

              <!-- Study 2: Neurological Screening -->
              <div class="challenge-visual-container">
                <h3 style="font-size: 1.2rem; margin-bottom: 1rem; color: #0f172a;">
                  Study 2: Multi-Neurological Disease Early Screening Algorithm
                </h3>

                <div style="background: #f8fafc; padding: 1.5rem; border-radius: 8px; border: 1px solid #e2e8f0;">
                  <h4 style="font-size: 1rem; margin-bottom: 1rem; color: #334155; font-weight: 600;">Research Overview
                  </h4>
                  <p style="font-size: 0.95rem; color: #475569; line-height: 1.7; margin-bottom: 1rem;">
                    Focusing on the <strong>'Temporal Complexity'</strong> of the response rather than simple pupil size
                    changes, we extracted 47 high-dimensional biomarkers including frequency analysis, Sample Entropy,
                    and Fractal Dimension. We developed a model to predict the risk of 10 neurological diseases,
                    including Parkinson's, Alzheimer's, and Diabetic Retinopathy.
                  </p>

                  <div class="challenge-visual-grid"
                    style="display: flex; gap: 1rem; justify-content: center; flex-wrap: wrap; margin-bottom: 1.5rem;">
                    <!-- 1. Setup -->
                    <figure
                      style="flex: 1 1 auto; max-width: 260px; background: #fff; padding: 0.5rem; border: 1px solid #e2e8f0; border-radius: 8px;">
                      <img src="../assets/images/research/phase4_study2_experiment_setup.jpg" alt="Experiment Setup"
                        style="width: auto; max-width: 100%; height: auto; border-radius: 4px;">
                      <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                        High-precision Pupil Response Measurement Setup
                      </figcaption>
                    </figure>

                    <!-- 2. Risk Distribution -->
                    <figure
                      style="flex: 1 1 auto; max-width: 350px; background: #fff; padding: 0.5rem; border: 1px solid #e2e8f0; border-radius: 8px;">
                      <img src="../assets/images/research/phase4_study2_risk_distribution.jpg"
                        alt="Disease Risk Distribution"
                        style="width: auto; max-width: 100%; height: auto; border-radius: 4px;">
                      <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                        Risk Distribution by Disease Category
                      </figcaption>
                    </figure>

                    <!-- 3. Correlation Matrix -->
                    <figure
                      style="flex: 1 1 auto; max-width: 330px; background: #fff; padding: 0.5rem; border: 1px solid #e2e8f0; border-radius: 8px;">
                      <img src="../assets/images/research/phase4_study2_correlation_matrix.jpg"
                        alt="Biomarker Correlation Matrix"
                        style="width: auto; max-width: 100%; height: auto; border-radius: 4px;">
                      <figcaption style="margin-top: 0.5rem; font-size: 0.8rem; color: #64748b; text-align: center;">
                        Pupillometric Biomarker Correlation Matrix
                      </figcaption>
                    </figure>
                  </div>

                  <div class="challenge-visual-grid"
                    style="display: flex; flex-wrap: wrap; gap: 1rem; margin: 1.5rem 0;">
                    <!-- Informational Cards for Biomarkers -->
                    <div
                      style="flex: 1 1 300px; background: #fff; padding: 1rem; border-radius: 6px; border: 1px solid #e2e8f0; box-shadow: 0 1px 2px rgba(0,0,0,0.05);">
                      <h5 style="font-size: 0.9rem; color: #0f172a; margin-bottom: 0.5rem;">ðŸ“Š Sample Entropy Analysis
                      </h5>
                      <p style="font-size: 0.85rem; color: #64748b; line-height: 1.5;">
                        Pupil response complexity (Entropy) was significantly higher for <strong>human face
                          stimuli</strong> than for geometric shapes (F=12.47, p&lt;0.001). This suggests specialized
                        autonomic responses involved in social stimulus processing and serves as an indicator of fine
                        autonomic regulation.
                      </p>
                    </div>
                    <div
                      style="flex: 1 1 300px; background: #fff; padding: 1rem; border-radius: 6px; border: 1px solid #e2e8f0; box-shadow: 0 1px 2px rgba(0,0,0,0.05);">
                      <h5 style="font-size: 0.9rem; color: #0f172a; margin-bottom: 0.5rem;">ðŸŽ¯ Disease Sensitivity</h5>
                      <p style="font-size: 0.85rem; color: #64748b; line-height: 1.5;">
                        The developed algorithm showed high detection sensitivity, particularly for <strong>Diabetic
                          Retinopathy (60.9%)</strong>, followed by Multiple Sclerosis and Parkinson's Disease. This
                        proves the strong potential of pupillometry as a non-invasive tool for early screening of
                        retinal and central nervous system damage.
                      </p>
                    </div>
                  </div>


                </div>
              </div>
            </div>
          </div>
        </div>
    </section>
  </main>

  <script src="../assets/js/main.js?v=2.2"></script>
</body>

</html>